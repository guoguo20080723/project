"0","#import the dataset"
"0","all <- read.csv(""all.csv"")"
"0","#from factor to character"
"0","all$title<-as.character(all$title)"
"0","#visualize most closely related words (words that appear together most often)"
"0","bigram <-"
"0","  all %>%"
"0","  #from sentences to two consecutive words"
"0","  unnest_tokens(bigram, title, token = ""ngrams"", n = 2) %>%"
"0","  separate(bigram, c(""word1"", ""word2""), sep = "" "") %>%"
"0","  #drop stopwords and digits"
"0","  filter(!word1 %in% stop_words$word) %>%"
"0","  filter(!word2 %in% stop_words$word) %>%"
"0","  filter(!str_detect(word1,""\\d"")) %>%"
"0","  filter(!str_detect(word2,""\\d"")) %>%"
"0","  count(word1, word2, topic, sort = TRUE) %>%"
"0","  #drop words with low frequency"
"0","  filter(n > 20) %>%"
"0","  graph_from_data_frame()"
"0",""
"0","#produce a network of bigrams"
"0","ggraph(bigram, layout = ""fr"") +"
"0","  geom_edge_link(aes(edge_alpha=n, color=topic), "
"0","                 edge_width=1.5) +"
"0","  geom_node_point(size=2, alpha=0.5) +"
"0","  geom_node_text(aes(label = name), alpha=0.7,"
"0","                 hjust = 1, vjust=1, size=3) +"
"0","  theme_void() +"
"0","  scale_edge_alpha(guide = 'none') +"
"0","  theme(legend.position=""bottom"") +"
"0","  theme(legend.text = element_text(size = 8))+"
"0","  theme(legend.title = element_blank())"
